{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract faces from pictures of people \n",
    "### Instrutions:\n",
    "- Place photos of people (one face visible) in the folder called \"./people\"\n",
    "- Replace my photo titled \"Rajeev.jpg\" with a piture of your face for testing on a webcam\n",
    "- Faces are extracted using the haarcascade_frontalface_default detector model\n",
    "- Extracted faces are placed in the folder called \"./group_of_faces\"\n",
    "#### We are extracting the faces needed for our one-shot learning model, it will load 5 extracted faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below extracts faces from images and places them in the folder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "# Loading out HAARCascade Face Detector \n",
    "face_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Directory of image of persons we'll be extracting faces frommy\n",
    "mypath = \"./people/\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected image names\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    person_image = cv2.imread(mypath+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image, 1.3, 5)\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    path = \"./group_of_faces/\" + \"face_\" + image_name \n",
    "    cv2.imwrite(path, roi)\n",
    "    cv2.imshow(\"face\", roi)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load our VGGFaceModel \n",
    "- This block of code defines the VGGFace model (which we use later) and loads the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#author Sefik Ilkin Serengil\n",
    "#you can find the documentation of this code from the following link: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def loadVggFaceModel():\n",
    "    \"\"\"Loads the VGGFace model defined in the function\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #you can download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "    from keras.models import model_from_json\n",
    "    model.load_weights('vgg_face_weights.h5')\n",
    "\n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "    return vgg_face_descriptor\n",
    "\n",
    "model = loadVggFaceModel()\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test model using your Webcam\n",
    "This code looks up the faces you extracted in the \"group_of_faces\" folder and uses the similarity (Cosine Similarity) to detect which faces is most similar to the one being extracted with your webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points to your extracted faces\n",
    "people_pictures = \"./group_of_faces/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = model.predict(preprocess_image('./group_of_faces/%s.jpg' % (person_face)))[0,:]\n",
    "\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "#Open Webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w > 100: #Adjust accordingly if your webcam resoluation is higher\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0\n",
    "            for i in all_people_faces:\n",
    "                person_name = i\n",
    "                representation = all_people_faces[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                if(similarity < 0.30):\n",
    "                    cv2.putText(img, person_name[5:], (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    found = 1\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == 0): #if found image is not in our people database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a video\n",
    "### Since we're using the Friends TV Series characters, let's extract the faces from the images I placed in the \"./friends\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "# Loading out HAARCascade Face Detector \n",
    "face_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Directory of image of persons we'll be extracting faces frommy\n",
    "mypath = \"./friends/\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected image names\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    person_image = cv2.imread(mypath+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image, 1.3, 5)\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    path = \"./friends_faces/\" + \"face_\" + image_name \n",
    "    cv2.imwrite(path, roi)\n",
    "    cv2.imshow(\"face\", roi)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, we load our faces from the \"friends_faces\" directory and we run our face classifier model our test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points to your extracted faces\n",
    "people_pictures = \"./friends_faces/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = model.predict(preprocess_image('./friends_faces/%s.jpg' % (person_face)))[0,:]\n",
    "\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "#Open Webcame\n",
    "#cap = cv2.VideoCapture(0) \n",
    "cap = cv2.VideoCapture('testfriends.mp4')\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.resize(img, (640, 360)) # Re-size video to as smaller size to improve face detection speed\n",
    "    faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w > 13: \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0\n",
    "            for i in all_people_faces:\n",
    "                person_name = i\n",
    "                representation = all_people_faces[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                if(similarity < 0.30):\n",
    "                    cv2.putText(img, person_name[5:], (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                    found = 1\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == 0): #if found image is not in our people database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "#kill open cv things\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
